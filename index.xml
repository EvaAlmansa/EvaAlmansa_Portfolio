<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Eva Almansa on Resume in English</title>
    <link>https://evaalmansa.github.io/EvaAlmansa_Portfolio/</link>
    <description>Recent content in Eva Almansa on Resume in English</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 06 May 2023 11:25:05 -0400</lastBuildDate><atom:link href="https://evaalmansa.github.io/EvaAlmansa_Portfolio/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>About</title>
      <link>https://evaalmansa.github.io/EvaAlmansa_Portfolio/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://evaalmansa.github.io/EvaAlmansa_Portfolio/about/</guid>
      <description>Eva Almansa I am a Marie Skłodowska-Curie Early Stage Researcher (ESR03) in the Visual Computing (ViC) group at the Center for Advanced Studies, Research, and Development in Sardinia (CRS4). I am awarded a fellowship (2020-2023) from the EVOCATION innovative training network under H2020. I hold a Bachelor Degree in Computer Science and Artificial Intelligence (2015) and a Master Degree of Data Science (2017) from the University of Granada, Spain.</description>
    </item>
    
    <item>
      <title>Projects</title>
      <link>https://evaalmansa.github.io/EvaAlmansa_Portfolio/projects/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://evaalmansa.github.io/EvaAlmansa_Portfolio/projects/</guid>
      <description>Advanced Visual and Geometric Computing 3D Capture Display and Fabrication Period: [ 2018 - 2023 ] Acronym: EVOCATION Funder: EU H2020</description>
    </item>
    
    <item>
      <title>Conferences</title>
      <link>https://evaalmansa.github.io/EvaAlmansa_Portfolio/conferences/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://evaalmansa.github.io/EvaAlmansa_Portfolio/conferences/</guid>
      <description>SIGGRAPH 2023 Student Volunteer &amp;amp; Attendance in-person (Los Angeles, USA)
As Student Volunteer at SIGGRAPH 2023: SIGGRAPH 2022 Student Volunteer &amp;amp; Attendance (virtually)
As Student Volunteer at SIGGRAPH 2022: ICVSS 2022 Student
As student at International Computer Vision Summer School 2022 (ICVSS 2022) in Catania, Italy. Poster
Almansa et al. Indoor 3D Reconstruction from Omnidirectional Input (Poster).
Successfully completed the examination session
For more information, see my Test Certificate: &amp;ldquo;The examination paper was related to the courses (30 hours) delivered by the following world-renowned experts in the field, from both academia and industry.</description>
    </item>
    
    <item>
      <title>Multimedia</title>
      <link>https://evaalmansa.github.io/EvaAlmansa_Portfolio/multimedia/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://evaalmansa.github.io/EvaAlmansa_Portfolio/multimedia/</guid>
      <description> A brief introduction about my work on the EVOCATION project (recorded and edited by myself, around 3 minutes of video): My work’s summary (an extension of the previous video) on the EVOCATION project (recorded and edited by myself, around 20 minutes of video): Oral Presentation at PyConEs21 (starts at 3 h 11 min 11 sec): </description>
    </item>
    
    <item>
      <title>Contact</title>
      <link>https://evaalmansa.github.io/EvaAlmansa_Portfolio/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://evaalmansa.github.io/EvaAlmansa_Portfolio/contact/</guid>
      <description>Feel free to ask me anything about my work. I am delighted to expand my network of contacts.
Your Name Email Address An email address is required. Message </description>
    </item>
    
    <item>
      <title>Network</title>
      <link>https://evaalmansa.github.io/EvaAlmansa_Portfolio/partners/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://evaalmansa.github.io/EvaAlmansa_Portfolio/partners/</guid>
      <description>I reserve this space for all those people whom I would like to promote, whom I admire for their magnificent vocation.
Marta Almansa (Excellent) Digital Artist Speaks: Spanish / English / German Portfolio &amp;amp; Contact: https://drawingprozac.carrd.co/ </description>
    </item>
    
    <item>
      <title>[CVM 2023] Deep Panoramic Depth Prediction and Completion for Indoor Scenes</title>
      <link>https://evaalmansa.github.io/EvaAlmansa_Portfolio/post/chapter-4/</link>
      <pubDate>Sat, 06 May 2023 11:25:05 -0400</pubDate>
      
      <guid>https://evaalmansa.github.io/EvaAlmansa_Portfolio/post/chapter-4/</guid>
      <description>Abstract We introduce a novel end-to-end deep learning solution for rapidly estimating a dense spherical depth map of an indoor environment. Our input is a single equirectangular image registered with a sparse depth map, as provided by a variety of common capture setups. Depth is inferred by an efficient and lightweight single-branch network, which employs a dynamic gating system to process together dense visual data and sparse geometric data. We exploit the characteristics of typical man-made environments to efficiently compress multi-resolution features and find short- and long-range relations among scene parts.</description>
    </item>
    
    <item>
      <title>[IEEE TVCG 2022] Instant Automatic Emptying of Panoramic Indoor Scenes</title>
      <link>https://evaalmansa.github.io/EvaAlmansa_Portfolio/post/chapter-3/</link>
      <pubDate>Sun, 06 Nov 2022 11:25:05 -0400</pubDate>
      
      <guid>https://evaalmansa.github.io/EvaAlmansa_Portfolio/post/chapter-3/</guid>
      <description>Abstract Nowadays 360° cameras, capable to capture full environments in a single shot, are increasingly being used in a variety of Extended Reality (XR) applications that require specific Diminished Reality (DR) techniques to conceal selected classes of objects. In this work, we present a new data-driven approach that, from an input 360° image of a furnished indoor space automatically returns, with very low latency, an omnidirectional photorealistic view and architecturally plausible depth of the same scene emptied of all clutter.</description>
    </item>
    
    <item>
      <title>[TOG 2021] Deep3DLayout: 3D reconstruction of an indoor layout from a spherical panoramic image</title>
      <link>https://evaalmansa.github.io/EvaAlmansa_Portfolio/post/chapter-2/</link>
      <pubDate>Fri, 10 Dec 2021 11:15:58 -0400</pubDate>
      
      <guid>https://evaalmansa.github.io/EvaAlmansa_Portfolio/post/chapter-2/</guid>
      <description>Abstract Recovering the 3D shape of the bounding permanent surfaces of a room from a single image is a key component of indoor reconstruction pipelines. In this article, we introduce a novel deep learning technique capable to produce, at interactive rates, a tessellated bounding 3D surface from a single 360° image. Differently from prior solutions, we fully address the problem in 3D, significantly expanding the reconstruction space of prior solutions.</description>
    </item>
    
    <item>
      <title>[CVPR 2021] SliceNet: Deep Dense Depth Estimation From a Single Indoor Panorama Using a Slice-Based Representation</title>
      <link>https://evaalmansa.github.io/EvaAlmansa_Portfolio/post/chapter-1/</link>
      <pubDate>Tue, 02 Nov 2021 11:14:48 -0400</pubDate>
      
      <guid>https://evaalmansa.github.io/EvaAlmansa_Portfolio/post/chapter-1/</guid>
      <description>Abstract We introduce a novel deep neural network to estimate a depth map from a single monocular indoor panorama. The network directly works on the equirectangular projection, exploiting the properties of indoor 360 images. Starting from the fact that gravity plays an important role in the design and construction of man-made indoor scenes, we propose a compact representation of the scene into vertical slices of the sphere, and we exploit long- and short-term relationships among slices to recover the equirectangular depth map.</description>
    </item>
    
  </channel>
</rss>
